{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Masking, Activation, Input\n",
    "from quiver_engine.server import launch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('TFwCAandDO_10epoch_0.9705acc.json', 'r')\n",
    "\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"TFwCAandDO_10epoch_0.9705acc.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.save('TFwCAandDO_10epoch_0.9705acc.hdf5')\n",
    "loaded_model=load_model('TFwCAandDO_10epoch_0.9705acc.hdf5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{<tensorflow.python.keras.engine.training.Model at 0x28d09fc3048>: True,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x28d09fc3080>: True,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fc3160>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fc3860>: False,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x28d09fc3cf8>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fc3f60>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fd2438>: False,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x28d09fd28d0>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fd2b38>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fd2fd0>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fd74a8>: False,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x28d09fd7940>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fd7ba8>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fdb080>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fdb518>: False,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x28d09fdb9b0>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fdbc18>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fdf0f0>: False,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x28d09fdf588>: False,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x28d09fdfa20>: False,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x28d09fdfc88>: False,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x28d09fdfdd8>: False,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x28d0c675128>: False,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x28d0c675438>: True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.summary()\n",
    "loaded_model._get_trainable_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample/cat.1500.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-35488d44b609>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfull_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sample/cat.1500.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TFandKR\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'L'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TFandKR\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2766\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample/cat.1500.jpg'"
     ]
    }
   ],
   "source": [
    "full_path = 'sample/cat.1500.jpg'\n",
    "    \n",
    "image = load_img(full_path, target_size=(224, 224))\n",
    "image = img_to_array(image)\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "image = preprocess_input(image)\n",
    "pred = loaded_model.predict(image, verbose=0, batch_size=1)\n",
    "#lable = decode_predictions(y_pred, top = 1)\n",
    "classes = pred.argmax(axis=-1) # print 1 or 0 probability\n",
    "print (classes)\n",
    "accuracy = pred[0] # remove secound array\n",
    "#print(accuracy)\n",
    "\n",
    "if classes[0] == 1:\n",
    "    print(\"Lable: Dog\")\n",
    "    print(\"Accuracy:\",accuracy[1])\n",
    "else:\n",
    "    print(\"Lable: Cat\")\n",
    "    print(\"Accuracy:\",accuracy[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sample1.jpg\n",
      "[0]\n",
      "test_sample10.jpg\n",
      "[1]\n",
      "test_sample11.jpg\n",
      "[1]\n",
      "test_sample12.jpg\n",
      "[0]\n",
      "test_sample13.jpg\n",
      "[1]\n",
      "test_sample14.jpg\n",
      "[0]\n",
      "test_sample15.jpg\n",
      "[1]\n",
      "test_sample16.jpg\n",
      "[0]\n",
      "test_sample17.jpg\n",
      "[0]\n",
      "test_sample18.jpg\n",
      "[1]\n",
      "test_sample19.jpg\n",
      "[1]\n",
      "test_sample2.jpg\n",
      "[0]\n",
      "test_sample20.jpg\n",
      "[1]\n",
      "test_sample21.jpg\n",
      "[0]\n",
      "test_sample22.jpg\n",
      "[1]\n",
      "test_sample23.jpg\n",
      "[0]\n",
      "test_sample24.jpg\n",
      "[1]\n",
      "test_sample25.jpg\n",
      "[1]\n",
      "test_sample26.jpg\n",
      "[1]\n",
      "test_sample27.jpg\n",
      "[0]\n",
      "test_sample28.jpg\n",
      "[0]\n",
      "test_sample29.jpg\n",
      "[1]\n",
      "test_sample3.jpg\n",
      "[0]\n",
      "test_sample30.jpg\n",
      "[0]\n",
      "test_sample31.jpg\n",
      "[0]\n",
      "test_sample32.jpg\n",
      "[0]\n",
      "test_sample33.jpg\n",
      "[0]\n",
      "test_sample34.jpg\n",
      "[0]\n",
      "test_sample35.jpg\n",
      "[1]\n",
      "test_sample36.jpg\n",
      "[1]\n",
      "test_sample37.jpg\n",
      "[0]\n",
      "test_sample38.jpg\n",
      "[0]\n",
      "test_sample39.jpg\n",
      "[0]\n",
      "test_sample4.jpg\n",
      "[0]\n",
      "test_sample40.jpg\n",
      "[0]\n",
      "test_sample5.jpg\n",
      "[1]\n",
      "test_sample6.jpg\n",
      "[1]\n",
      "test_sample7.jpg\n",
      "[1]\n",
      "test_sample8.jpg\n",
      "[1]\n",
      "test_sample9.jpg\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('sample'):\n",
    "    print(file)\n",
    "    full_path = 'sample/' + file\n",
    "    \n",
    "    image = load_img(full_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    pred = loaded_model.predict(image, verbose=0, batch_size=1)\n",
    "    #lable = decode_predictions(y_pred, top = 1)\n",
    "    classes = pred.argmax(axis=-1) # print 1 or 0 probability\n",
    "    print (classes)\n",
    "    accuracy = pred[0] # remove secound array\n",
    "    #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\bugbo\\\\TFandKR\\\\cats_and_dogs\\\\test\\\\test')\n",
    "i=1\n",
    "for file in os.listdir():\n",
    "    src=file\n",
    "    dst=\"test_sample\"+str(i)+\".jpg\"\n",
    "    os.rename(src,dst)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TFandKR] *",
   "language": "python",
   "name": "conda-env-TFandKR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
